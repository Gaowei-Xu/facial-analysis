{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 3320.jpg\n",
      "554 3 0\n",
      "Processing frame 3321.jpg\n",
      "554 3 0\n",
      "Processing frame 3322.jpg\n",
      "558 5 4\n",
      "Processing frame 3323.jpg\n",
      "558 5 0\n",
      "Processing frame 3324.jpg\n",
      "558 5 0\n",
      "Processing frame 3325.jpg\n",
      "558 5 0\n",
      "Processing frame 3326.jpg\n",
      "558 5 0\n",
      "Processing frame 3327.jpg\n",
      "558 5 0\n",
      "Processing frame 3328.jpg\n",
      "558 5 0\n",
      "Processing frame 3329.jpg\n",
      "558 5 0\n",
      "Processing frame 3330.jpg\n",
      "558 5 0\n",
      "Processing frame 3331.jpg\n",
      "558 5 0\n",
      "Processing frame 3332.jpg\n",
      "559 5 1\n",
      "Processing frame 3333.jpg\n",
      "559 4 0\n",
      "Processing frame 3334.jpg\n",
      "560 5 1\n",
      "Processing frame 3335.jpg\n",
      "561 6 1\n",
      "Processing frame 3336.jpg\n",
      "561 5 0\n",
      "Processing frame 3337.jpg\n",
      "561 5 0\n",
      "Processing frame 3338.jpg\n",
      "561 4 0\n",
      "Processing frame 3339.jpg\n",
      "562 5 1\n",
      "Processing frame 3340.jpg\n",
      "562 4 0\n",
      "Processing frame 3341.jpg\n",
      "563 5 1\n",
      "Processing frame 3342.jpg\n",
      "563 4 0\n",
      "Processing frame 3343.jpg\n",
      "563 4 0\n",
      "Processing frame 3344.jpg\n",
      "564 5 1\n",
      "Processing frame 3345.jpg\n",
      "564 5 0\n",
      "Processing frame 3346.jpg\n",
      "564 5 0\n",
      "Processing frame 3347.jpg\n",
      "564 5 0\n",
      "Processing frame 3348.jpg\n",
      "564 5 0\n",
      "Processing frame 3349.jpg\n",
      "564 5 0\n",
      "Processing frame 3350.jpg\n",
      "564 5 0\n",
      "Processing frame 3351.jpg\n",
      "564 5 0\n",
      "Processing frame 3352.jpg\n",
      "564 5 0\n",
      "Processing frame 3353.jpg\n",
      "564 5 0\n",
      "Processing frame 3354.jpg\n",
      "564 5 0\n",
      "Processing frame 3355.jpg\n",
      "564 5 0\n",
      "Processing frame 3356.jpg\n",
      "564 5 0\n",
      "Processing frame 3357.jpg\n",
      "564 5 0\n",
      "Processing frame 3358.jpg\n",
      "564 5 0\n",
      "Processing frame 3359.jpg\n",
      "564 5 0\n",
      "Processing frame 3360.jpg\n",
      "564 5 0\n",
      "Processing frame 3361.jpg\n",
      "564 5 0\n",
      "Processing frame 3362.jpg\n",
      "564 5 0\n",
      "Processing frame 3363.jpg\n",
      "564 5 0\n",
      "Processing frame 3364.jpg\n",
      "564 5 0\n",
      "Processing frame 3365.jpg\n",
      "564 5 0\n",
      "Processing frame 3366.jpg\n",
      "564 5 0\n",
      "Processing frame 3367.jpg\n",
      "564 5 0\n",
      "Processing frame 3368.jpg\n",
      "564 4 0\n",
      "Processing frame 3369.jpg\n",
      "564 5 0\n",
      "Processing frame 3370.jpg\n",
      "564 3 0\n",
      "Processing frame 3371.jpg\n",
      "565 4 1\n",
      "Processing frame 3372.jpg\n",
      "565 4 0\n",
      "Processing frame 3373.jpg\n",
      "565 4 0\n",
      "Processing frame 3374.jpg\n",
      "565 4 0\n",
      "Processing frame 3375.jpg\n",
      "565 4 0\n",
      "Processing frame 3376.jpg\n",
      "565 4 0\n",
      "Processing frame 3377.jpg\n",
      "565 4 0\n",
      "Processing frame 3378.jpg\n",
      "565 4 0\n",
      "Processing frame 3379.jpg\n",
      "565 4 0\n",
      "Processing frame 3380.jpg\n",
      "565 4 0\n",
      "Processing frame 3381.jpg\n",
      "565 4 0\n",
      "Processing frame 3382.jpg\n",
      "565 4 0\n",
      "Processing frame 3383.jpg\n",
      "565 3 0\n",
      "Processing frame 3384.jpg\n",
      "565 3 0\n",
      "Processing frame 3385.jpg\n",
      "565 3 0\n",
      "Processing frame 3386.jpg\n",
      "565 3 0\n",
      "Processing frame 3387.jpg\n",
      "565 3 0\n",
      "Processing frame 3388.jpg\n",
      "565 3 0\n",
      "Processing frame 3389.jpg\n",
      "565 3 0\n",
      "Processing frame 3390.jpg\n",
      "565 3 0\n",
      "Processing frame 3391.jpg\n",
      "565 3 0\n",
      "Processing frame 3392.jpg\n",
      "565 3 0\n",
      "Processing frame 3393.jpg\n",
      "565 3 0\n",
      "Processing frame 3394.jpg\n",
      "565 3 0\n",
      "Processing frame 3395.jpg\n",
      "565 3 0\n",
      "Processing frame 3396.jpg\n",
      "565 3 0\n",
      "Processing frame 3397.jpg\n",
      "565 3 0\n",
      "Processing frame 3398.jpg\n",
      "570 5 5\n",
      "Processing frame 3399.jpg\n"
     ]
    }
   ],
   "source": [
    "import boto3 \n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from io import BufferedReader\n",
    "\n",
    "\n",
    "recog_result_root_dir = './recognition_results/'\n",
    "if not os.path.exists(recog_result_root_dir):\n",
    "    os.makedirs(recog_result_root_dir)\n",
    "\n",
    "client=boto3.client('rekognition')\n",
    "\n",
    "\n",
    "def same_face(face_1_bytes, face_2_bytes):\n",
    "    try:\n",
    "        response=client.compare_faces(\n",
    "            SimilarityThreshold=85,\n",
    "            SourceImage={'Bytes': face_1_bytes},\n",
    "            TargetImage={'Bytes': face_2_bytes})\n",
    "\n",
    "        matched = len(response['FaceMatches']) > 0\n",
    "        return matched\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "# rec =  [left, right, bottom, top]\n",
    "def calculateIOU(rec1, rec2):\n",
    "    intersect_l = max(rec1[0],rec2[0])\n",
    "    intersect_r = min(rec1[1],rec2[1])\n",
    "    intersect_b = max(rec1[2],rec2[2])\n",
    "    intersect_t = min(rec1[3],rec2[3])\n",
    "    if intersect_l >= intersect_r or intersect_b >= intersect_t:\n",
    "        return 0.0\n",
    "    else:\n",
    "        S_rect1 = (rec1[1]-rec1[0])*(rec1[3]-rec1[2])\n",
    "        S_rect2 = (rec2[1]-rec2[0])*(rec2[3]-rec2[2])\n",
    "        intersect = (intersect_r - intersect_l)*(intersect_t - intersect_b)\n",
    "        iou = float(intersect) / (S_rect1 + S_rect2 - intersect)\n",
    "        return iou\n",
    "    \n",
    "\n",
    "def identify_already_appear_before(faces_collector, \n",
    "                                   faces_in_last_frame, \n",
    "                                   compare_face_bytes, \n",
    "                                   current_face, \n",
    "                                   image_height,\n",
    "                                   image_width,\n",
    "                                   attributes):\n",
    "    \n",
    "    # 输入人脸的位置\n",
    "    base_height = int(attributes['BoundingBox']['Height'] * image_height)\n",
    "    base_left = int(attributes['BoundingBox']['Left'] * image_width)\n",
    "    base_top = int(attributes['BoundingBox']['Top'] * image_height)\n",
    "    base_width = int(attributes['BoundingBox']['Width'] * image_width)\n",
    "    \n",
    "    # 先基于面积来评估追踪\n",
    "    max_iou = -1.0\n",
    "    matched_face_id = -1\n",
    "    for idx, face_obj in enumerate(faces_in_last_frame):\n",
    "        height = int(face_obj['attributes']['BoundingBox']['Height'] * image_height)\n",
    "        left = int(face_obj['attributes']['BoundingBox']['Left'] * image_width)\n",
    "        top = int(face_obj['attributes']['BoundingBox']['Top'] * image_height)\n",
    "        width = int(face_obj['attributes']['BoundingBox']['Width'] * image_width)\n",
    "        \n",
    "        # 计算over_lap\n",
    "        iou = calculateIOU(\n",
    "            [base_left, base_left + base_width, base_top, base_top + base_height],\n",
    "            [left, left + width, top, top + height],\n",
    "        )\n",
    "        \n",
    "        if iou > max_iou:\n",
    "            max_iou = iou\n",
    "            matched_face_id = face_obj['id']\n",
    "            \n",
    "    if max_iou > 0.5:        \n",
    "        for k, obj in enumerate(faces_collector):\n",
    "            if obj['id'] == matched_face_id:\n",
    "                faces_collector[k]['bytes'] = compare_face_bytes\n",
    "                faces_collector[k]['attributes'] = attributes\n",
    "                faces_collector[k]['face'] = current_face\n",
    "                return True, copy.deepcopy(faces_collector[k])\n",
    "\n",
    "    # 如果基于面积评估追踪失败，则进行人脸比对操作，比较费时\n",
    "    for idx, face_obj in enumerate(faces_collector):\n",
    "        if same_face(face_obj['bytes'], compare_face_bytes):\n",
    "            faces_collector[idx]['bytes'] = compare_face_bytes\n",
    "            faces_collector[idx]['attributes'] = attributes\n",
    "            faces_collector[idx]['face'] = current_face\n",
    "            return True, copy.deepcopy(faces_collector[idx])\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "\n",
    "frames_root_dir = './raw_volvo_demo_video_frames/'\n",
    "results_root_dir = './face_detection_results/'\n",
    "\n",
    "# 存储不同的人的信息，包括其ID和最新的某一帧中检测出的人脸图像\n",
    "# faces_collector = list()\n",
    "# face_id = 0\n",
    "# faces_in_last_frame = list()\n",
    "\n",
    "faces_collector = list()\n",
    "start_index = 3320\n",
    "pkls = [ele for ele in os.listdir(recog_result_root_dir) if (ele.endswith('.pkl') and (int(ele.split('.pkl')[0]) < start_index))]\n",
    "pkls = sorted(pkls, key=lambda x:int(x.split('.')[0]))\n",
    "\n",
    "for pkl_name in pkls:\n",
    "    full_path = os.path.join(recog_result_root_dir, pkl_name)\n",
    "    faces_list = pickle.load(open(full_path, 'rb'))\n",
    "    \n",
    "    face_ids_in_collector = [obj['id'] for obj in faces_collector]\n",
    "    \n",
    "    for obj in faces_list:\n",
    "        if obj['id'] not in face_ids_in_collector:\n",
    "            faces_collector.append(obj)\n",
    "\n",
    "faces_in_last_frame = pickle.load(open(os.path.join(recog_result_root_dir, '{}.pkl'.format(start_index-1)), 'rb'))\n",
    "max_face_id = -1\n",
    "for face_obj in faces_in_last_frame:\n",
    "    if face_obj['id'] > max_face_id:\n",
    "        max_face_id = face_obj['id']\n",
    "face_id = max_face_id + 1\n",
    "\n",
    "\n",
    "# 每一帧中出现的人物信息，其元素为一个list\n",
    "faces_distribution = list()\n",
    "\n",
    "frames = [ele for ele in os.listdir(frames_root_dir) if ele.endswith('.jpg')]\n",
    "frames = sorted(frames, key=lambda x:int(x.split('.')[0]))\n",
    "\n",
    "\n",
    "for index, frame_name in enumerate(frames):\n",
    "    if index < start_index:\n",
    "        continue\n",
    "\n",
    "    print('Processing frame {}'.format(frame_name))\n",
    "    \n",
    "    # 加载原图和人脸检测（含各种属性）结果\n",
    "    frame_full_path = os.path.join(frames_root_dir, frame_name)\n",
    "    response_full_path = os.path.join(results_root_dir, frame_name.split('.')[0] + '.json')\n",
    "    image = cv2.imread(frame_full_path, cv2.IMREAD_COLOR)\n",
    "    response = json.load(open(response_full_path, 'r'))\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    \n",
    "    face_details = response['FaceDetails']\n",
    "\n",
    "    # 保存当前帧里面出现的人物信息\n",
    "    total_faces_in_current_frame = list() # 所有脸需要按照face_id从小到大排序\n",
    "    new_faces_in_current_frame  = list()\n",
    "        \n",
    "    # 遍历当前帧中检测到的每一个人脸\n",
    "    for face_idx in range(len(face_details)):\n",
    "        attributes = face_details[face_idx]\n",
    "        height = int(attributes['BoundingBox']['Height'] * image_height)\n",
    "        left = int(attributes['BoundingBox']['Left'] * image_width)\n",
    "        top = int(attributes['BoundingBox']['Top'] * image_height)\n",
    "        width = int(attributes['BoundingBox']['Width'] * image_width)\n",
    "        \n",
    "        current_face = image[top:top+height, left:left+width] \n",
    "        \n",
    "        margin = int(max(height, width) * 0.2)\n",
    "        min_height = top-margin if top-margin >= 0 else 0\n",
    "        max_height = top+height+margin if top+height+margin <= image_height else image_height\n",
    "        min_width = left-margin if left-margin >= 0 else 0\n",
    "        max_width = left+width+margin if left+width+margin <= image_width else image_width\n",
    "        margin_current_face = image[min_height:max_height, min_width:max_width] \n",
    "        \n",
    "        temp_path = 'face.jpg'\n",
    "        cv2.imwrite(temp_path, margin_current_face)\n",
    "        with open(temp_path, 'rb') as rf:\n",
    "            current_face_bytes = rf.read()\n",
    "        \n",
    "        if len(faces_collector) == 0:\n",
    "            new_faces_in_current_frame.append({\n",
    "                'face': current_face,\n",
    "                'bytes': current_face_bytes,\n",
    "                'id': face_id,\n",
    "                'attributes': attributes\n",
    "            })\n",
    "                \n",
    "            face_id += 1\n",
    "        else:   \n",
    "            already_appear, face_obj = identify_already_appear_before(\n",
    "                faces_collector, \n",
    "                faces_in_last_frame,\n",
    "                current_face_bytes, \n",
    "                current_face, \n",
    "                image_height,\n",
    "                image_width,\n",
    "                attributes)\n",
    "            \n",
    "            if already_appear:\n",
    "                total_faces_in_current_frame.append(face_obj)\n",
    "            else:\n",
    "                new_faces_in_current_frame.append({\n",
    "                    'face': current_face,\n",
    "                    'bytes': current_face_bytes,\n",
    "                    'id': face_id,\n",
    "                    'attributes': attributes\n",
    "                })\n",
    "\n",
    "                face_id += 1\n",
    "    \n",
    "    total_faces_in_current_frame.extend(new_faces_in_current_frame)\n",
    "    total_faces_in_current_frame = sorted(total_faces_in_current_frame, key=lambda x:x['id'])\n",
    "    faces_in_last_frame = copy.deepcopy(total_faces_in_current_frame)        \n",
    "        \n",
    "    faces_collector.extend(new_faces_in_current_frame)\n",
    "    faces_distribution.append(total_faces_in_current_frame)\n",
    "    \n",
    "    print(len(faces_collector), len(total_faces_in_current_frame), len(new_faces_in_current_frame))\n",
    "    \n",
    "    faces_record_dump_path = os.path.join(recog_result_root_dir, '{}.pkl'.format(frame_name.split('.')[0]))\n",
    "    with open(faces_record_dump_path, 'wb') as wf:\n",
    "        pickle.dump(total_faces_in_current_frame, wf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
